}
# Create LISA clusters for crime rates
columbus_sp$lisa_cluster <- lisa_clusters(columbus_sp$CRIME,
columbus_sp$local_moran,
columbus_sp$local_moran_p)
# Map the LISA clusters
tm_shape(columbus_sp) +
tm_fill("lisa_cluster",
palette = c("red", "blue", "pink", "lightblue", "white"),
title = "LISA Cluster") +
tm_borders() +
tm_layout(title = "LISA Cluster Map of Crime Rates",
legend.outside = TRUE)
# Create a function to classify LISA clusters
lisa_clusters <- function(var, lisa, p_value, p_threshold = 0.05) {
# Standardize the variable
z_var <- scale(var)
# Calculate spatial lag of standardized variable
lag_var <- lag.listw(queen_weights, z_var)
# Create classifications
clusters <- rep("Not Significant", length(var))
clusters[lisa > 0 & p_value <= p_threshold & z_var > 0 & lag_var > 0] <- "High-High"
clusters[lisa > 0 & p_value <= p_threshold & z_var < 0 & lag_var < 0] <- "Low-Low"
clusters[lisa < 0 & p_value <= p_threshold & z_var > 0 & lag_var < 0] <- "High-Low"
clusters[lisa < 0 & p_value <= p_threshold & z_var < 0 & lag_var > 0] <- "Low-High"
return(factor(clusters, levels = c("High-High", "Low-Low", "High-Low", "Low-High", "Not Significant")))
}
# Create LISA clusters for crime rates
columbus_sp$lisa_cluster <- lisa_clusters(columbus_sp$CRIME,
columbus_sp$local_moran,
columbus_sp$local_moran_p)
# Map the LISA clusters
tm_shape(columbus_sf) +
tm_fill("lisa_cluster",
palette = c("red", "blue", "pink", "lightblue", "white"),
title = "LISA Cluster") +
tm_borders() +
tm_layout(title = "LISA Cluster Map of Crime Rates",
legend.outside = TRUE)
# Create a function to classify LISA clusters
lisa_clusters <- function(var, lisa, p_value, p_threshold = 0.05) {
# Standardize the variable
z_var <- scale(var)
# Calculate spatial lag of standardized variable
lag_var <- lag.listw(queen_weights, z_var)
# Create classifications
clusters <- rep("Not Significant", length(var))
clusters[lisa > 0 & p_value <= p_threshold & z_var > 0 & lag_var > 0] <- "High-High"
clusters[lisa > 0 & p_value <= p_threshold & z_var < 0 & lag_var < 0] <- "Low-Low"
clusters[lisa < 0 & p_value <= p_threshold & z_var > 0 & lag_var < 0] <- "High-Low"
clusters[lisa < 0 & p_value <= p_threshold & z_var < 0 & lag_var > 0] <- "Low-High"
return(factor(clusters, levels = c("High-High", "Low-Low", "High-Low", "Low-High", "Not Significant")))
}
# Create LISA clusters for crime rates
columbus_sf$lisa_cluster <- lisa_clusters(columbus_sf$CRIME,
columbus_sf$local_moran,
columbus_sf$local_moran_p)
# Map the LISA clusters
tm_shape(columbus_sf) +
tm_fill("lisa_cluster",
palette = c("red", "blue", "pink", "lightblue", "white"),
title = "LISA Cluster") +
tm_borders() +
tm_layout(title = "LISA Cluster Map of Crime Rates",
legend.outside = TRUE)
# Combine results from different methods for a comprehensive view
columbus_sp$insight <- "Standard approach"
# Areas with significant crime clustering (from LISA)
high_crime_clusters <- (columbus_sp$lisa_cluster == "High-High")
# Areas that are hotspots from Getis-Ord Gi*
hotspots <- (columbus_sp$hotspot == "Hotspot (95%)" | columbus_sp$hotspot == "Hotspot (99%)")
# Combine insights
columbus_sp$insight[high_crime_clusters & hotspots] <- "Priority intervention area"
columbus_sp$insight[high_crime_clusters & !hotspots] <- "Emerging cluster"
columbus_sp$insight[!high_crime_clusters & hotspots] <- "Potential concern"
# Map the combined insights
tm_shape(columbus_sp) +
tm_fill("insight", palette = c("red", "orange", "yellow", "grey"),
title = "Intervention Priority") +
tm_borders() +
tm_layout(title = "Crime Intervention Priority Areas",
legend.outside = TRUE)
# Install necessary packages (if not already installed)
packages <- c("sf", "spdep", "tmap", "tmaptools", "spData", "dplyr",
"ggplot2", "classInt", "RColorBrewer", "viridis", "knitr")
install.packages(packages[!packages %in% installed.packages()[,"Package"]],
repos = "https://cran.r-project.org/")
# Load the packages
library(tmap)       # For thematic maps
library(tmaptools)  # Additional mapping tools
library(dplyr)      # For data manipulation
library(ggplot2)    # For plotting
library(classInt)   # For classification
library(RColorBrewer) # For color palettes
library(viridis)    # For color palettes
library(knitr)      # For nice table output
library(sp)
# Set tmap to plot mode
# tmap_mode("plot")
# Load required packages
library(sf)
library(spdep)
library(spData)
# Load the Columbus polygon shapefile correctly
# columbus_poly <- st_read(system.file("shapes/columbus.shp", package="spData"))
columbus_poly <- sf::st_read(system.file("shapes/columbus.gpkg", package="spData")[1])
# columbus_poly <- st_read(system.file("columbus.shp", package="spData"))
# View the first few rows
head(columbus_poly)
# Create a simple map to visualize the areas
tm_shape(columbus_poly) +
tm_fill("CRIME", style = "quantile", palette = "Reds", title = "Crime Rate") +
tm_borders() +
tm_layout(title = "Crime Rates in Columbus Neighborhoods",
legend.outside = TRUE)
# Summary statistics
summary(columbus_poly[, c("CRIME", "HOVAL", "INC")])
# Histograms of key variables
par(mfrow = c(1, 3))
hist(columbus_poly$CRIME, main = "Crime Rate", xlab = "Crime Rate", col = "lightblue")
par(mfrow = c(1, 1))
# Create a series of choropleth maps for key variables
tm_shape(columbus_poly) +
tm_fill(c("CRIME", "HOVAL", "INC"),
style = "quantile",
palette = list("Reds", "Blues", "Greens"),
title = c("Crime Rate", "Housing Value", "Income")) +
tm_borders() +
tm_facets(ncol = 3) +
tm_layout(legend.outside = TRUE)
# Summary statistics
summary(columbus_poly[, c("CRIME", "HOVAL", "INC")])
# Histograms of key variables
par(mfrow = c(1, 1))
hist(columbus_poly$CRIME, main = "Crime Rate", xlab = "Crime Rate", col = "lightblue")
par(mfrow = c(1, 1))
# Create a series of choropleth maps for key variables
tm_shape(columbus_poly) +
tm_fill(c("CRIME", "HOVAL", "INC"),
style = "quantile",
palette = list("Reds", "Blues", "Greens"),
title = c("Crime Rate", "Housing Value", "Income")) +
tm_borders() +
tm_facets(ncol = 3) +
tm_layout(legend.outside = TRUE)
# Summary statistics
summary(columbus_poly[, c("CRIME", "HOVAL", "INC")])
# Histograms of key variables
par(mfrow = c(1, 1))
hist(columbus_poly$CRIME, main = "Crime Rate", xlab = "Crime Rate", col = "lightblue")
par(mfrow = c(1, 1))
# Create a series of choropleth maps for key variables
tm_shape(columbus_poly) +
tm_fill(c("CRIME"),
style = "quantile",
palette = list("Reds"),
title = c("Crime Rate")) +
tm_borders() +
tm_facets(ncol = 3) +
tm_layout(legend.outside = TRUE)
# Summary statistics
summary(columbus_poly[, c("CRIME", "HOVAL", "INC")])
# Histograms of key variables
par(mfrow = c(1, 1))
hist(columbus_poly$CRIME, main = "Crime Rate", xlab = "Crime Rate", col = "lightblue")
par(mfrow = c(1, 1))
# Create a series of choropleth maps for key variables
tm_shape(columbus_poly) +
tm_fill(c("CRIME"),
style = "quantile",
palette = list("Reds"),
title = c("Crime Rate")) +
tm_borders() +
tm_facets(ncol = 1) +
tm_layout(legend.outside = TRUE)
# Create queen contiguity weights
queen_nb <- poly2nb(columbus_poly, queen = TRUE)
summary(queen_nb)
print(queen_nb)
# Extract coordinates
columbus_sp <- as(columbus_poly, "Spatial")
coords <- coordinates(columbus_sp)
# Plot the queen contiguity network
plot(columbus_sp, border = "grey")
plot(queen_nb, coords, add = TRUE, col = "red", lwd = 1)
title("Queen Contiguity Neighbors")
# Convert to weights list object
queen_weights <- nb2listw(queen_nb, style = "W")
library(tmap)
tm_shape(columbus_poly) +
tm_fill("CRIME", style = "quantile", palette = "Reds", title = "Crime Rate") +
tm_borders() +
# Highlight the first polygon
tm_shape(columbus_poly[3, ]) +
tm_borders(lwd = 3, col = "blue") +
tm_layout(title = "",
legend.outside = TRUE)
# Calculate local Moran's I for crime rates
lisa_crime <- localmoran(columbus_sp$CRIME, queen_weights)
head(lisa_crime)
# Add local Moran statistics to our spatial data
columbus_sp$local_moran <- lisa_crime[, 1]  # Local Moran's I statistic
columbus_sp$local_moran_p <- lisa_crime[, 5]  # P-value
columbus_sf <- st_as_sf(columbus_sp)
# Map the local Moran's I values
tm_shape(columbus_sf) +
tm_fill("local_moran", style = "jenks", palette = "-RdBu",
midpoint = 0, title = "Local Moran's I") +
tm_borders() +
tm_layout(title = "Local Spatial Autocorrelation of Crime Rates",
legend.outside = TRUE)
# Map the significance of local Moran's I
tm_shape(columbus_sf) +
tm_fill("local_moran_p", style = "fixed",
breaks = c(0, 0.01, 0.05, 0.1, 1),
palette = "-Greens", title = "p-value") +
tm_borders() +
tm_layout(title = "Significance of Local Moran's I",
legend.outside = TRUE)
View(lisa_crime)
library(tmap)
tm_shape(columbus_sp) +
tm_fill("HOVAL", style = "quantile", palette = "Reds", title = "Housing Price") +
tm_borders() +
# Highlight the first polygon
tm_borders(lwd = 3, col = "blue") +
tm_layout(title = "",
legend.outside = TRUE)
# Load necessary libraries and data
library(sf)
library(spdep)
library(spData)
library(tmap)
library(sp)
# Load columbus shapefile
columbus_poly <- st_read(system.file("shapes/columbus.shp", package="spData"))
# Load necessary libraries and data
library(sf)
library(spdep)
library(spData)
library(tmap)
library(sp)
# Load columbus shapefile
columbus_poly <- sf::st_read(system.file("shapes/columbus.gpkg", package="spData")[1])
columbus_sp <- as(columbus_poly, "Spatial")
# Create queen contiguity weights
queen_nb <- poly2nb(columbus_sp, queen = TRUE)
queen_weights <- nb2listw(queen_nb, style = "W")
# Calculate global Moran's I for housing values
moran_hoval <- moran.test(columbus_sp$HOVAL, queen_weights)
print(moran_hoval)
# Create Moran scatterplot
moran.plot(columbus_sp$HOVAL, queen_weights,
labels = as.character(columbus_sp$POLYID),
xlab = "Housing Value (standardized)",
ylab = "Spatially Lagged Housing Value")
library(tmap)
tm_shape(columbus_sp) +
tm_fill("HOVAL", style = "quantile", palette = "Reds", title = "Housing Price") +
tm_borders() +
# Highlight the first polygon
tm_borders(lwd = 3, col = "blue") +
tm_layout(title = "",
legend.outside = TRUE)
# Load necessary libraries and data
library(sf)
library(spdep)
library(spData)
library(tmap)
library(sp)
# Load columbus shapefile
columbus_poly <- sf::st_read(system.file("shapes/columbus.gpkg", package="spData")[1])
columbus_sp <- st_as_sf(columbus_poly)
# Create queen contiguity weights
queen_nb <- poly2nb(columbus_sp, queen = TRUE)
queen_weights <- nb2listw(queen_nb, style = "W")
# Calculate global Moran's I for housing values
moran_hoval <- moran.test(columbus_sp$HOVAL, queen_weights)
print(moran_hoval)
# Create Moran scatterplot
moran.plot(columbus_sp$HOVAL, queen_weights,
labels = as.character(columbus_sp$POLYID),
xlab = "Housing Value (standardized)",
ylab = "Spatially Lagged Housing Value")
library(tmap)
tm_shape(columbus_sp) +
tm_fill("HOVAL", style = "quantile", palette = "Reds", title = "Housing Price") +
tm_borders() +
# Highlight the first polygon
tm_borders(lwd = 3, col = "blue") +
tm_layout(title = "",
legend.outside = TRUE)
library(tmap)
tm_shape(columbus_sp) +
tm_fill("HOVAL", style = "quantile", palette = "Reds", title = "Housing Price") +
tm_borders() +
# Highlight the first polygon
tm_layout(title = "",
legend.outside = TRUE)
library(tmap)
tm_shape(columbus_sp) +
tm_fill("HOVAL", style = "quantile", palette = "Reds", title = "Housing Price") +
tm_borders() +
# Highlight the first polygon
tm_layout(title = "",
legend.outside = TRUE)
# Load necessary libraries and data
library(sf)
library(spdep)
library(spData)
library(tmap)
library(sp)
# Load columbus shapefile
columbus_poly <- sf::st_read(system.file("shapes/columbus.gpkg", package="spData")[1])
columbus_sp <- st_as_sf(columbus_poly)
tm_shape(columbus_sp) +
tm_fill("HOVAL", style = "quantile", palette = "Reds", title = "Housing Price") +
tm_borders() +
# Highlight the first polygon
tm_layout(title = "",
legend.outside = TRUE)
# Create queen contiguity weights
queen_nb <- poly2nb(columbus_sp, queen = TRUE)
queen_weights <- nb2listw(queen_nb, style = "W")
# Calculate global Moran's I for housing values
moran_hoval <- moran.test(columbus_sp$HOVAL, queen_weights)
print(moran_hoval)
# Create Moran scatterplot
moran.plot(columbus_sp$HOVAL, queen_weights,
labels = as.character(columbus_sp$POLYID),
xlab = "Housing Value (standardized)",
ylab = "Spatially Lagged Housing Value")
# Summary statistics
summary(columbus_poly[, c("CRIME")])
# Histograms of key variables
par(mfrow = c(1, 1))
hist(columbus_poly$CRIME, main = "Crime Rate", xlab = "Crime Rate", col = "lightblue")
par(mfrow = c(1, 1))
# Create a series of choropleth maps for key variables
tm_shape(columbus_poly) +
tm_fill(c("CRIME"),
style = "quantile",
palette = list("Reds"),
title = c("Crime Rate")) +
tm_borders() +
tm_facets(ncol = 1) +
tm_layout(legend.outside = TRUE)
# Calculate Moran's I for crime rates using queen weights
moran_crime_queen <- moran.test(columbus_sp$CRIME, queen_weights)
print(moran_crime_queen)
# Create Moran scatterplot for crime rates
moran.plot(columbus_sp$CRIME, queen_weights,
labels = as.character(columbus_sp$POLYID),
xlab = "Crime Rate (standardized)",
ylab = "Spatially Lagged Crime Rate")
# Calculate local Moran's I for Housing Value
lisa_crime <- localmoran(columbus_sp$HOVAL, queen_weights)
head(lisa_crime)
# Add local Moran statistics to our spatial data
columbus_sp$local_moran <- lisa_crime[, 1]  # Local Moran's I statistic
columbus_sp$local_moran_p <- lisa_crime[, 5]  # P-value
columbus_sf <- st_as_sf(columbus_sp)
# Map the local Moran's I values
tm_shape(columbus_sf) +
tm_fill("local_moran", style = "jenks", palette = "-RdBu",
midpoint = 0, title = "Local Moran's I") +
tm_borders() +
tm_layout(title = "Local Spatial Autocorrelation of Housing Price",
legend.outside = TRUE)
# Map the significance of local Moran's I
tm_shape(columbus_sf) +
tm_fill("local_moran_p", style = "fixed",
breaks = c(0, 0.01, 0.05, 0.1, 1),
palette = "-Greens", title = "p-value") +
tm_borders() +
tm_layout(title = "Significance of Local Moran's I",
legend.outside = TRUE)
# Install necessary packages (if not already installed)
packages <- c("sf", "spdep", "tmap", "tmaptools", "spData", "dplyr",
"ggplot2", "classInt", "RColorBrewer", "viridis", "knitr")
install.packages(packages[!packages %in% installed.packages()[,"Package"]],
repos = "https://cran.r-project.org/")
# Load the packages
library(tmap)       # For thematic maps
library(tmaptools)  # Additional mapping tools
library(dplyr)      # For data manipulation
library(ggplot2)    # For plotting
library(classInt)   # For classification
library(RColorBrewer) # For color palettes
library(viridis)    # For color palettes
library(knitr)      # For nice table output
library(sp)
# Set tmap to plot mode
# tmap_mode("plot")
# Load required packages
library(sf)
library(spdep)
library(spData)
# Load the Columbus polygon shapefile correctly
# columbus_poly <- st_read(system.file("shapes/columbus.shp", package="spData"))
columbus_poly <- sf::st_read(system.file("shapes/columbus.gpkg", package="spData")[1])
# columbus_poly <- st_read(system.file("columbus.shp", package="spData"))
# View the first few rows
head(columbus_poly)
# Create a simple map to visualize the areas
tm_shape(columbus_poly) +
tm_fill("CRIME", style = "quantile", palette = "Reds", title = "Crime Rate") +
tm_borders() +
tm_layout(title = "Crime Rates in Columbus Neighborhoods",
legend.outside = TRUE)
# Summary statistics
summary(columbus_poly[, c("CRIME")])
# Histograms of key variables
par(mfrow = c(1, 1))
hist(columbus_poly$CRIME, main = "Crime Rate", xlab = "Crime Rate", col = "lightblue")
par(mfrow = c(1, 1))
# Create a series of choropleth maps for key variables
tm_shape(columbus_poly) +
tm_fill(c("CRIME"),
style = "quantile",
palette = list("Reds"),
title = c("Crime Rate")) +
tm_borders() +
tm_facets(ncol = 1) +
tm_layout(legend.outside = TRUE)
# Create queen contiguity weights
queen_nb <- poly2nb(columbus_poly, queen = TRUE)
summary(queen_nb)
print(queen_nb)
# Extract coordinates
columbus_sp <- as(columbus_poly, "Spatial")
coords <- coordinates(columbus_sp)
# Plot the queen contiguity network
plot(columbus_sp, border = "grey")
plot(queen_nb, coords, add = TRUE, col = "red", lwd = 1)
title("Queen Contiguity Neighbors")
# Convert to weights list object
queen_weights <- nb2listw(queen_nb, style = "W")
library(tmap)
tm_shape(columbus_poly) +
tm_fill("CRIME", style = "quantile", palette = "Reds", title = "Crime Rate") +
tm_borders() +
# Highlight the first polygon
tm_shape(columbus_poly[3, ]) +
tm_borders(lwd = 3, col = "blue") +
tm_layout(title = "",
legend.outside = TRUE)
# Create rook contiguity weights
rook_nb <- poly2nb(columbus_poly, queen = FALSE)
summary(rook_nb)
# Plot the rook contiguity network
plot(columbus_sp, border = "grey")
plot(rook_nb, coords, add = TRUE, col = "red", lwd = 1)
title("Rook Contiguity Neighbors")
# Convert to weights list object
rook_weights <- nb2listw(rook_nb, style = "W")
# Calculate Moran's I for crime rates using queen weights
moran_crime_queen <- moran.test(columbus_sp$CRIME, queen_weights)
print(moran_crime_queen)
# Create Moran scatterplot for crime rates
moran.plot(columbus_sp$CRIME, queen_weights,
labels = as.character(columbus_sp$POLYID),
xlab = "Crime Rate (standardized)",
ylab = "Spatially Lagged Crime Rate")
# Calculate local Moran's I for crime rates
lisa_crime <- localmoran(columbus_sp$CRIME, queen_weights)
head(lisa_crime)
# Add local Moran statistics to our spatial data
columbus_sp$local_moran <- lisa_crime[, 1]  # Local Moran's I statistic
columbus_sp$local_moran_p <- lisa_crime[, 5]  # P-value
columbus_sf <- st_as_sf(columbus_sp)
# Map the local Moran's I values
tm_shape(columbus_sf) +
tm_fill("local_moran", style = "jenks", palette = "-RdBu",
midpoint = 0, title = "Local Moran's I") +
tm_borders() +
tm_layout(title = "Local Spatial Autocorrelation of Crime Rates",
legend.outside = TRUE)
# Map the significance of local Moran's I
tm_shape(columbus_sf) +
tm_fill("local_moran_p", style = "fixed",
breaks = c(0, 0.01, 0.05, 0.1, 1),
palette = "-Greens", title = "p-value") +
tm_borders() +
tm_layout(title = "Significance of Local Moran's I",
legend.outside = TRUE)
# Create a function to classify LISA clusters
lisa_clusters <- function(var, lisa, p_value, p_threshold = 0.05) {
# Standardize the variable
z_var <- scale(var)
# Calculate spatial lag of standardized variable
lag_var <- lag.listw(queen_weights, z_var)
# Create classifications
clusters <- rep("Not Significant", length(var))
clusters[lisa > 0 & p_value <= p_threshold & z_var > 0 & lag_var > 0] <- "High-High"
clusters[lisa > 0 & p_value <= p_threshold & z_var < 0 & lag_var < 0] <- "Low-Low"
clusters[lisa < 0 & p_value <= p_threshold & z_var > 0 & lag_var < 0] <- "High-Low"
clusters[lisa < 0 & p_value <= p_threshold & z_var < 0 & lag_var > 0] <- "Low-High"
return(factor(clusters, levels = c("High-High", "Low-Low", "High-Low", "Low-High", "Not Significant")))
}
# Create LISA clusters for crime rates
columbus_sf$lisa_cluster <- lisa_clusters(columbus_sf$CRIME,
columbus_sf$local_moran,
columbus_sf$local_moran_p)
# Map the LISA clusters
tm_shape(columbus_sf) +
tm_fill("lisa_cluster",
palette = c("red", "blue", "pink", "lightblue", "white"),
title = "LISA Cluster") +
tm_borders() +
tm_layout(title = "LISA Cluster Map of Crime Rates",
legend.outside = TRUE)
